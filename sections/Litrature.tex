\documentclass[../main/main.tex]{subfiles}

\begin{document}
	
	\section{Literature Review} \label{Literature}
	 \shortcite{fridrich2009steganography} was the first one to investigate the idea of cover synthesis. \shortcite{fridrich2009steganography} He proposed an image hashing method for achieving secret embedding. First selecting an appropriate image for the secret and sending it, then the receiver will calculate the image hash to reveal the secret information. However, this is not practical because of low secret embedding capacity. \shortcite{otori2007data} proposed a method of synthesizing texture images for embedding secret data by using smart techniques of generating repetitive texture patterns through feature learning of a sample image. They used a sample texture and some color points generated using the secret message and used this to construct dense texture images. Then this was improved to have more capacity by \shortcite{wu2014steganography}. 
	 
	 Even though there were this improvements in the area of cover synthesis steganography, the main leap was not achieved until the discovery of \gls{GAN}s in \shortcite{goodfellow2014generative}. After the discovery of \gls{GAN}s,  \shortcite{volkhonskiy2017steganographic} proposed a model for generating image containers using \gls{DCGAN}. They used \gls{DCGAN} to generate cover images that are more secure in hiding the secret information. This approach is found to be more secure than the traditional steganographic models. \shortcite{shi2017ssgan} used this concept and improved the \gls{GAN} performance by using different type of \gls{GAN} called \gls{WGAN}.\shortcite{arjovsky2017wasserstein} This greatly improved the convergence speed, training stability and image quality. This and some other papers proposed similar improvements and variations of cover synthesis algorithms.\shortcite{tang2017automatic}\shortcite{hayes2017generating}
	 
	 As noted in \shortcite{Zhang2019} this previous papers still rely on cover modification after the cover synthesis phase. This is a poor utilization of \gls{GAN}s. Since \gls{GAN}s are powerful generators they are powerful samplers. Therefore, exploiting this feature will result in better frameworks with no modification. In the following subsection three papers that have achieved steganography without embedding (\gls{SWE}) .\shortcite{Zhang2019}\shortcite{Hu2018}\shortcite{Ke} will be explained.
	 
	 \subsection{\gls{SWE}}
	  \shortcite{Ke} first proposed a generative steganography called \gls{GSK}. In \gls{GSK}, the secret messages are generated by a cover image using a generator rather than embedded into the cover, thus resulting in no modifications in the cover. The \gls{GSK} framework consists of two \gls{GAN}s called the Message \gls{GAN} and the Cover \gls{GAN}. The message \gls{GAN} is used to control the output by using feature codes. Feature codes are attributes in the samples of the dataset that are independent and give meaning to the generated images. Examples given are skin color, \textquotedblleft fat or thin\textquotedblright, \textit{etc.} Using this feature code and a noise vector the message \gls{GAN} will generate not only realistic images but also images that conform to this feature set. The message \gls{GAN} was implemented with \gls{infoGAN} \shortcite{chen2016infogan}. The cover \gls{GAN} has the main functionality of making the cover image a necessary input to determine the generation of secret message according to Kerckhoff's principle.\shortcite{kerckhoff1883} The cover \gls{GAN} is composed of three neural networks that are structured based on adversarial neural symmetric cryptography\shortcite{abadi2016learning}, in which Alice and Bob both neural networks are trained to minimize what Eve a third neural network learns about the communication by eavesdropping. Despite this remarkable design one of the main pitfall of this framework is its low capacity. Since the secret hiding space is the feature code of the image it imposes a small capacity. The other main pitfall is the quality of the generated images.  
	   % explain this more
	  
	 According to \shortcite{Zhang2019} the term \textquotedblleft generative steganography\textquotedblright  was first introduced in \shortcite{Liu2018}.They used \gls{ACGAN} which have an input of class label in addition to the noise vector of a standard \gls{GAN}.  The main idea of the method in \shortcite{Liu2018} is that the class label of \gls{GAN}s is replaced with the secret information as a driver to generate hidden image directly, and then extract the secret information from the hidden image through the discriminator. 
	 
	  \shortcite{Hu2018} proposed an image \gls{SWE} method based on deep convolutional generative adversarial networks. They map the secret information into a noise vector and use the trained generator neural network model to generate the carrier image based on the noise vector. No modification or embedding operations are required during the process of image generation, and the information contained in the image can be extracted successfully by another neural network, called the extractor, after training. This framework has an advantage of high capacity with relative capacity of 9.16e-3 and remarkable recovery accuracy that could reach even up to 98\%.However it greatly suffers from poor quality of generated images. The authors reported that due to poor image quality some images did not escape detection by staganalysis tools.  According to the paper one the main drawback of this framework is the usage of \gls{DCGAN}s.
	  
	  Recently \shortcite{Zhang2019} proposed data-driven information hiding scheme called ‘‘generative steganography by sampling’’ (\gls{GSS}). This method uses semantic image inpainting. The message is written in advance to an uncorrupted region that needs to be retained in the corrupted image. Then, the corrupted image with the secret message is fed into a Generator trained by a \gls{GAN} for semantic completion. They treated generative steganography as constrained image inpainting problem. Instead of generating a whole image they started from a corrupted image and used a \gls{GAN} for image completion. Before this corrupted image is fed to the generator the secret message is inserted in the uncorrupted regions of the corrupted image using Cardan grille. They have achieved good relative capacity that could be up to 1.10e-2. However just like the above mentioned papers they suffer from poor image quality. They used \gls{DCGAN} for the generator and they have admitted that the use of a more powerful generator will enhance the quality of the generated images. The other main contribution of this paper is the introduction of a new security criterion motivated by $\epsilon$-security of \shortcite{Cachin1998}. They used the Jenson-Shanon divergence which is the loss metric of \gls{DCGAN} to measure the steganographic security. However if the two probability distributions whose divergence is being measured are so far apart that there is no overlap between the two the Jenson-Shanon divergence is constant which is a fatal problem for gradient based learning, since it would make the gradient zero at this point. Though this problem is noted in the paper, they choose Jenson-Shanon because they used \gls{DCGAN} for the generator. 
	 
\end{document}